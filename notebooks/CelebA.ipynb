{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParticleEM/ParEM_neural_latent_variable_model/blob/master/notebooks/CelebA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNEy6xRqKKxZ"
      },
      "source": [
        "# Description\n",
        "\n",
        "Introductory blabla\n",
        "\n",
        "### Dataset description:\n",
        "\n",
        "Dataset consists of $M$ images $y = (y^{m})_{m=1}^M$.\n",
        "\n",
        "### Model description:\n",
        "\n",
        "$$\n",
        "p_\\theta (x,y) = \\prod_{m=1}^M p_\\theta(x^{m}, y^{m})\n",
        "$$\n",
        "where\n",
        "$$\n",
        "p_\\theta(x,y)= p_\\theta(y|x)p(x)\n",
        "$$\n",
        "with\n",
        "$$\n",
        "p_\\theta(y|x) = \\mathcal{N}(y|\\mu_\\theta(x), \\sigma^2 I),\n",
        "$$\n",
        "where $\\mu_\\theta(\\cdot)$ is a neural network parameterised by $\\theta$, and $p(x) = \\mathcal{N}(x|0,I)$. \n",
        "\n",
        "The neural net consists of \n",
        "\n",
        "$$\\mu_\\theta =  \\tanh\\circ c_\\theta\\circ d_\\theta \\circ d_\\theta \\circ proj_\\theta$$\n",
        "\n",
        "where\n",
        "\n",
        "\n",
        "*   $\\phi$ is a GELU activation function.\n",
        "*   $c_\\theta$ is a transpose convolutional layer.\n",
        "*   $proj_\\theta=\\phi \\circ c_\\theta \\circ \\phi\\circ l_\\theta$. Maps from $\\mathbb{R}^{D_x}$ to $4\\times 16\\times 16$, where $D_x$ is dimension of latent variable.\n",
        "*   $l_\\theta$ is a linear layer.\n",
        "*   $d_\\theta=\\phi \\circ conv_\\theta \\circ \\phi\\circ conv_\\theta + I$ (HAS A SKIP CONNECTION).\n",
        "*   $conv_\\theta$ is a convolutional layer.\n",
        "\n",
        "\n",
        "### Algorithm description:\n",
        "\n",
        "For $k=1,\\dots,K$.\n",
        "\\begin{align*}\n",
        "    \\theta_{k+1} &= \\theta_k + \\frac{h}{N}\\sum_{n=1}^N \\sum_{m\\in\\mathcal{I}} \\nabla_\\theta \\log p_{\\theta_k}\n",
        "(X^{n,m}_k, y^{m}) \\\\\n",
        "X^{n,m}_{k+1}&=X^{n,m}_k + h\\nabla_x \\log p_{\\theta_k}\n",
        "(X^{n,m}_k, y^{m}) + \\sqrt{2h} W^{n,m}_k \\quad \\forall m = 1, .., M, n= 1,..., N.\n",
        "\\end{align*}\n",
        "\n",
        "where $\\mathcal{I}$ is a random subset of $M_b$ images in $\\mathcal{D}$.\n",
        "\n",
        "\n",
        "Describe stopping criterion: early stop bla bla.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceG5fAENPfr6"
      },
      "source": [
        "# Import modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz47uMXqKYf5"
      },
      "source": [
        "First, we load the modules we need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ssu1R-nnaGpW"
      },
      "outputs": [],
      "source": [
        "# Declare dicitonary like object for storing config variables:\n",
        "import argparse\n",
        "args = argparse.Namespace()\n",
        "args.seed = 1 # Seed for PRNs\n",
        "\n",
        "# Data setttings\n",
        "args.n_images = 40000 # M\n",
        "\n",
        "# Training settings\n",
        "args.n_epochs = 500 # K\n",
        "args.n_batch = 128 # M_b\n",
        "args.n_sampler_batch = 750\n",
        "args.early_stopping = True # Turn on early stopping\n",
        "\n",
        "# Model Settings\n",
        "args.x_dim = 64 # D_x\n",
        "args.theta_opt = 'rmsprop' # Lambda premultiplying matrix\n",
        "args.likelihood_var = 0.3 ** 2 # \\sigma^2\n",
        "\n",
        "# EM Settings\n",
        "args.theta_step_size = 1e-3 # h_\\theta\n",
        "args.q_step_size = 1e-4 # h_q\n",
        "args.clip_grad = False\n",
        "args.n_particles = 10 # N\n",
        "\n",
        "# Synthesis settings\n",
        "args.corrupt_std = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLCqb7XBKj2b"
      },
      "outputs": [],
      "source": [
        "# Install missing modules\n",
        "%%capture\n",
        "!pip install torchtyping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpxVMzKzQGaN"
      },
      "outputs": [],
      "source": [
        "# Import standard modules\n",
        "import torch\n",
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X55L4TEtl385",
        "outputId": "4d44b6d9-1396-4c87-80f9-dd6648838f51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ParEM_VAE'...\n",
            "remote: Enumerating objects: 291, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 291 (delta 26), reused 56 (delta 23), pack-reused 230\u001b[K\n",
            "Receiving objects: 100% (291/291), 42.93 KiB | 6.13 MiB/s, done.\n",
            "Resolving deltas: 100% (134/134), done.\n"
          ]
        }
      ],
      "source": [
        "# Import custom modules\n",
        "!rm -rf ParEM_VAE\n",
        "!git clone https://pareem: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@github.com/ParticleEM/ParEM_VAE.git\n",
        "sys.path.append(\"/content/ParEM_VAE/\")\n",
        "from parem.model import G\n",
        "from parem.pga import PGA, optimisers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C83FbhuRRXc_"
      },
      "source": [
        "# Set paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqT0ajsqRVKi"
      },
      "outputs": [],
      "source": [
        "# Mounts drive to VM in colab.\n",
        "%%capture\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=False)\n",
        "\n",
        "GDRIVE_CELEBA_PATH = Path(\"/content/gdrive/MyDrive/celeba/celeba\", force_remount=False)\n",
        "LOCAL_CELEBA_ROOT_PATH = Path(\"/content/\")\n",
        "LOCAL_CELEBA_DIR_PATH = Path(\"/content/\") / \"celeba\"\n",
        "CHECKPOINT_DIR = Path(\"/content/gdrive/MyDrive/particle-em/celeba\")\n",
        "CHECKPOINT_DIR.mkdir(exist_ok=True, parents=True)\n",
        "assert GDRIVE_CELEBA_PATH.is_dir()\n",
        "if not LOCAL_CELEBA_DIR_PATH.is_dir():\n",
        "  !cp -r $GDRIVE_CELEBA_PATH -d /content/\n",
        "  img_aligned_zip_path = LOCAL_CELEBA_DIR_PATH / \"img_align_celeba.zip\"\n",
        "  !unzip $img_aligned_zip_path -d $LOCAL_CELEBA_DIR_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbrwaBFyRb4P"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXOewTu5Piuw",
        "outputId": "c9e1859c-598a-46bf-d6dc-287498d157a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "........................................................................................................................................................................................................Total number of images 40000\n"
          ]
        }
      ],
      "source": [
        "#@title Load dataset\n",
        "from parem.celeba import get_celeba\n",
        "\n",
        "dataset = get_celeba(LOCAL_CELEBA_DIR_PATH / \"img_align_celeba\", args.n_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "JtEGiGKkS0pm"
      },
      "outputs": [],
      "source": [
        "#@title Divvy up dataset in batches for training.\n",
        "\n",
        "train = torch.utils.data.DataLoader(dataset, batch_size=args.n_batch, shuffle=True, pin_memory=True)\n",
        "larger_batch_train = torch.utils.data.DataLoader(dataset, batch_size=args.n_sampler_batch, shuffle=True, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ue1zy2hKjmlb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchtyping import TensorType\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "optimisers = {'sgd': torch.optim.SGD,\n",
        "              'adagrad': torch.optim.Adagrad,\n",
        "              'rmsprop': torch.optim.RMSprop,\n",
        "              }\n",
        "\n",
        "\n",
        "class PGA:\n",
        "    def __init__(self,\n",
        "                 model,\n",
        "                 n_images: int,\n",
        "                 dl,\n",
        "                 q_step_size: float = 1e-2,\n",
        "                 theta_step_size: float = 1e-2,\n",
        "                 n_particles: int = 30,\n",
        "                 device=\"cpu\",\n",
        "                 clip_grad=False,\n",
        "                 theta_opt='sgd',):\n",
        "\n",
        "        self.n_particles = n_particles\n",
        "        self.model = model\n",
        "        self.q_step_size = q_step_size\n",
        "        self.device = device\n",
        "        self.clip_grad = clip_grad\n",
        "        self.dl = dl\n",
        "        self.n_images = n_images\n",
        "\n",
        "        # Initialize samples\n",
        "        self._particles = model.init_x([n_images, n_particles],\n",
        "                                       device=self.device)\n",
        "\n",
        "        # Declare theta optimiser\n",
        "        if type(theta_opt) == str:\n",
        "            self.theta_opt = optimisers[theta_opt](model.parameters(),\n",
        "                                                   lr=theta_step_size)\n",
        "        elif isinstance(theta_opt, torch.optim.Optimizer):\n",
        "            self.theta_opt = theta_opt\n",
        "\n",
        "    def loss(self,\n",
        "             images,#: TensorType[\"n_batch\", \"image_dimensions\": ...],\n",
        "             particles: TensorType[\"n_batch\", \"n_particles\",\"x_dim\"]\n",
        "             ) -> TensorType[()]:\n",
        "        \"\"\"\n",
        "        \\frac{M}{N|images|}\\sum_{n=1}^N\\sum_{m in images}p_{\\theta_k}(X_k^{n,m}, y^m)\n",
        "        \"\"\"\n",
        "        log_p = self.model.log_p_v(images, particles)\n",
        "        assert not log_p.isnan().any(), \"log_p is nan.\"\n",
        "        return - (1. / images.shape[0]) * log_p.mean()\n",
        "\n",
        "    def step(self,\n",
        "             img_batch,#: TensorType[\"n_batch\", \"image_dimensions\":...],\n",
        "             idx: TensorType[\"n_batch\"]):\n",
        "\n",
        "        # Compute theta gradients:\n",
        "        self.model.train()  # ??\n",
        "        self.theta_opt.zero_grad()  # Zero theta gradients\n",
        "        self.model = self.model.requires_grad_(True)  # ??\n",
        "\n",
        "        # Evaluate loss function:\n",
        "        loss = self.loss(img_batch, self._particles[idx].to(img_batch.device))\n",
        "\n",
        "        # Backpropagate theta gradients:\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip theta gradients if clipping requested:\n",
        "        if self.clip_grad:\n",
        "            clip_grad_norm_(self.model.parameters(), 100)\n",
        "\n",
        "        # Update particles batch by batch (s.t. device memory is not exceeded):\n",
        "        self.model.eval()\n",
        "        self.model = self.model.requires_grad_(False)\n",
        "        for imgs, idx in self.dl:\n",
        "            # Select particles to be updated in this iteration:\n",
        "            sub_particles = (self._particles[idx].detach().clone()\n",
        "                                 .to(img_batch.device).requires_grad_(True))\n",
        "            # Send relevant images to device:\n",
        "            imgs = imgs.to(img_batch.device)\n",
        "\n",
        "            # Compute x gradients:\n",
        "            log_p_v = self.model.log_p_v(imgs, sub_particles).sum()\n",
        "            x_grad = torch.autograd.grad(log_p_v, sub_particles)[0]\n",
        "\n",
        "            # Take a gradient step for this batch's particles:\n",
        "            self._particles[idx] += (self.q_step_size\n",
        "                                     * x_grad.to(self._particles.device))\n",
        "\n",
        "        # Add noise to all particles:\n",
        "        self._particles += ((2 * self.q_step_size) ** 0.5\n",
        "                            * torch.randn_like(self._particles))\n",
        "\n",
        "        # Update theta:\n",
        "        self.theta_opt.step()\n",
        "\n",
        "        # Return value of loss function:\n",
        "        return loss.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rduJTaL4RPB7"
      },
      "outputs": [],
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = G(args.x_dim, sigma2=args.likelihood_var, nc=3, use_bn=True).to(DEVICE)\n",
        "pga = PGA(model,\n",
        "          args.n_images,\n",
        "          larger_batch_train,\n",
        "          device='cpu',\n",
        "          theta_step_size=args.theta_step_size,\n",
        "          q_step_size=args.q_step_size,\n",
        "          n_particles=args.n_particles,\n",
        "          clip_grad=args.clip_grad,\n",
        "          theta_opt=args.theta_opt,\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2uiBWF1KPSu"
      },
      "outputs": [],
      "source": [
        "# Import modules necessary for training loop\n",
        "%%capture\n",
        "!pip install wandb\n",
        "import wandb\n",
        "import pickle\n",
        "from torchvision.utils import make_grid\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Swb3lAyyVe0h"
      },
      "outputs": [],
      "source": [
        "#@title Plotting function\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "def show(imgs):\n",
        "    if not isinstance(imgs, list):\n",
        "        imgs = [imgs]\n",
        "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False, dpi=400)\n",
        "    for i, img in enumerate(imgs):\n",
        "        img = img.detach()\n",
        "        img = F.to_pil_image(img)\n",
        "        axs[0, i].imshow(np.asarray(img))\n",
        "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "weq8_THjRHw-",
        "outputId": "7b5042b2-0cad-434c-dd97-45e00efe6a1e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjenninglim\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220808_003020-3ad8xzdx</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/jenninglim/particle-em-celeba/runs/3ad8xzdx\" target=\"_blank\">robust-waterfall-68</a></strong> to <a href=\"https://wandb.ai/jenninglim/particle-em-celeba\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".........................................................................................................................................................................................................................................................................................................................Epoch 0: 6015.171044: Loss 3025.247257317979\n",
            ".........................................................................................................................................................................................................................................................................................................................Epoch 1: 5999.059761: Loss 1250.8347676920052\n",
            ".........................................................................................................................................................................................................................................................................................................................Epoch 2: 5998.474289: Loss 845.9626667644269\n",
            ".........................................................................................................................................................................................................................................................................................................................Epoch 3: 5998.508234: Loss 682.838738682171\n",
            ".........................................................................................................................................................................................................................................................................................................................Epoch 4: 5998.528633: Loss 594.3983515047798\n",
            ".............................................................................................................................................................................................................................................................................................."
          ]
        }
      ],
      "source": [
        "#@title Main training loop\n",
        "to_range_0_1 = lambda x: (x + 1.) / 2.\n",
        "\n",
        "wandb.login()\n",
        "wandb.init(\n",
        "    project=\"particle-em-celeba\",\n",
        "    config = vars(args),\n",
        ")\n",
        "\n",
        "wandb.watch(model, log=\"all\", log_freq=10)\n",
        "\n",
        "losses = []\n",
        "for epoch in range(args.n_epochs):\n",
        "  model.train()\n",
        "  avg_loss = 0\n",
        "  start = time.time()\n",
        "  for imgs, idx in train:\n",
        "      imgs = imgs.to(device=DEVICE)\n",
        "      loss = pga.step(imgs, idx)\n",
        "      avg_loss += loss\n",
        "      print(\".\", end='')\n",
        "  end = time.time()\n",
        "  avg_loss = avg_loss / len(train) #/ args.n_images\n",
        "  losses.append(avg_loss)\n",
        "\n",
        "\n",
        "  print(f\"Epoch {epoch}: {end - start:2f}: Loss {avg_loss}\")\n",
        "\n",
        "  # Save model\n",
        "  (CHECKPOINT_DIR / wandb.run.name / \"model\").mkdir(exist_ok=True, parents=True)\n",
        "  torch.save(model.state_dict(), CHECKPOINT_DIR / wandb.run.name / \"model\" / f\"{epoch}_model\")\n",
        "  (CHECKPOINT_DIR / wandb.run.name / \"particles\").mkdir(exist_ok=True, parents=True)\n",
        "  with open(CHECKPOINT_DIR / wandb.run.name / \"particles\" / f\"{epoch}_particles\", 'wb') as f:\n",
        "    pickle.dump(pga._particles, f)\n",
        "  \n",
        "\n",
        "  with torch.no_grad():\n",
        "    n_cols = 8\n",
        "    n_rows = 8\n",
        "    mean = torch.mean(pga._particles, [0, 1, 3, 4])\n",
        "    cov = torch.cov(pga._particles.flatten(0,1).flatten(1, 3).transpose(0, 1))\n",
        "    normal_approx = torch.distributions.multivariate_normal.MultivariateNormal(loc = mean, covariance_matrix=cov)\n",
        "    z = normal_approx.sample(sample_shape=torch.Size([n_cols * n_rows])).unsqueeze(-1).unsqueeze(-1)\n",
        "    samples = to_range_0_1(model(z.to(DEVICE)))\n",
        "    grid = make_grid(samples)\n",
        "    fig = show(grid)\n",
        "    samples = wandb.Image(grid)\n",
        "    (CHECKPOINT_DIR / wandb.run.name / \"grid\").mkdir(exist_ok=True, parents=True)\n",
        "    plt.savefig(CHECKPOINT_DIR / wandb.run.name / \"grid\" / f\"{epoch}_samples.png\", bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "    model.eval()\n",
        "    torch.random.manual_seed(1)\n",
        "    original_img = to_range_0_1(train.dataset[0][0]).unsqueeze(0)\n",
        "    particle_img = to_range_0_1(model(pga._particles[0, :10].to(DEVICE))).to(original_img.device)\n",
        "    grid = make_grid(torch.concat([original_img, particle_img], dim=0))\n",
        "    particles = wandb.Image(grid)\n",
        "\n",
        "    mse_n_samples = 100\n",
        "    mse_n_particles = args.n_particles\n",
        "    original_img = to_range_0_1(torch.stack(dataset[:mse_n_samples][0], dim=0).unsqueeze(1))\n",
        "    particle_img = to_range_0_1(model(pga._particles[:mse_n_samples, :mse_n_particles].contiguous().to(DEVICE))).to(original_img.device)\n",
        "    assert original_img.shape == torch.Size([mse_n_samples, 1, 3, 32, 32])\n",
        "    assert particle_img.shape == torch.Size([mse_n_samples, mse_n_particles, 3, 32, 32])\n",
        "    mse = (((particle_img - original_img) ** 2).sum([-1, -2, -3]).mean()).item()\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    n_missing_img = 10\n",
        "    missing_imgs = torch.stack(dataset[:n_missing_img][0], dim=0)\n",
        "    init_x = torch.randn(n_missing_img, args.x_dim, 1, 1, requires_grad=True)\n",
        "    opt = torch.optim.Adam([init_x], 1e-2)\n",
        "    mse = torch.nn.MSELoss()\n",
        "    missing_mask = torch.zeros_like(missing_imgs, dtype=torch.bool)\n",
        "\n",
        "    for i in range(10, 22):\n",
        "      for j in range(10, 22):\n",
        "            missing_mask[..., i, j] = True\n",
        "\n",
        "    for i in range(1000):\n",
        "      opt.zero_grad()\n",
        "      filled_imgs = model.forward(init_x.to(DEVICE)).to('cpu')\n",
        "      loss = mse(filled_imgs[~missing_mask], missing_imgs[~missing_mask])\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "\n",
        "\n",
        "    filled_imgs = to_range_0_1(filled_imgs)\n",
        "    missing_imgs = to_range_0_1(missing_imgs)\n",
        "    input = missing_imgs.detach().clone()\n",
        "    input[missing_mask] = 0.2\n",
        "\n",
        "    for i in range(n_missing_img):\n",
        "      grid = make_grid(torch.concat([input[[i]], filled_imgs[[i]], missing_imgs[[i]]], dim=0))\n",
        "      fig = show(grid)\n",
        "      (CHECKPOINT_DIR / wandb.run.name / \"impaint\" / f\"{epoch}\").mkdir(exist_ok=True, parents=True)\n",
        "      plt.savefig(CHECKPOINT_DIR / wandb.run.name / \"impaint\" / f\"{epoch}\" / f\"{i}.png\", bbox_inches='tight')\n",
        "      plt.close(fig)\n",
        "\n",
        "  if epoch > 2 and args.early_stopping:\n",
        "    if epoch - np.argmin(losses) > 10:\n",
        "      print(\"Early Stop\")\n",
        "      break;\n",
        "\n",
        "    # import matplotlib.pyplot as plt\n",
        "    # particles = pga._particles[:, :mse_n_particles].flatten(0,1).flatten(-3,-1).cpu()\n",
        "    # plt.scatter(particles[:,0], particles[:,1])\n",
        "    # plt.show()\n",
        "  wandb.log({'particles': particles,\n",
        "              'samples': samples,\n",
        "              \"loss\" : avg_loss,\n",
        "              'mse': mse,\n",
        "              'theta_step_size' : pga.theta_opt.param_groups[0]['lr'],\n",
        "              })\n",
        "  plt.clf()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCq4Mj9oVULQ"
      },
      "outputs": [],
      "source": [
        "wandb.run.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RI-XWj3t2XVP"
      },
      "outputs": [],
      "source": [
        "[for param in model.parameters():]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "CelebA.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}