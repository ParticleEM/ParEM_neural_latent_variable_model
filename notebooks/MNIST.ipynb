{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParticleEM/ParEM_neural_latent_variable_model/blob/master/notebooks/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceG5fAENPfr6"
      },
      "source": [
        "# Import modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TLCqb7XBKj2b"
      },
      "outputs": [],
      "source": [
        "# Install missing modules\n",
        "%%capture\n",
        "!pip install torchtyping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UpxVMzKzQGaN"
      },
      "outputs": [],
      "source": [
        "# Import standard modules\n",
        "import torch\n",
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "#from pathlib import Path\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X55L4TEtl385",
        "outputId": "2283235f-844d-49d7-f90d-422dd689aaf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ParEM_neural_latent_variable_model'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 74 (delta 27), reused 28 (delta 7), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (74/74), done.\n"
          ]
        }
      ],
      "source": [
        "# Import custom modules\n",
        "!rm -rf ParEM_neural_latent_variable_model\n",
        "!git clone https://pareem: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@github.com/ParticleEM/ParEM_neural_latent_variable_model.git\n",
        "sys.path.append(\"/content/ParEM_neural_latent_variable_model/\")\n",
        "from parem.model import G\n",
        "from parem.pga import PGA\n",
        "from parem.dataset_loaders import get_mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set config variables"
      ],
      "metadata": {
        "id": "3S7vBXKyCtX3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ssu1R-nnaGpW"
      },
      "outputs": [],
      "source": [
        "# Declare dicitonary-like object for storing config variables:\n",
        "args = argparse.Namespace()\n",
        "\n",
        "# Data setttings\n",
        "args.n_images = 1000  # M: training set size \n",
        "\n",
        "# Training settings\n",
        "args.n_epochs = 500 # K: total number of iterations\n",
        "args.n_batch = 128 # M_b: batch size for theta updates\n",
        "args.seed = 1 # Seed for PRNG\n",
        "# Device on which to carry out computations:\n",
        "args.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Model Settings\n",
        "args.x_dim = 10  # d_x: dimension of latent space\n",
        "args.likelihood_var = 0.3 ** 2  # sigma^2\n",
        "\n",
        "# PGA Settings\n",
        "args.h = 5e-5 # h: step size \n",
        "args.lambd = 1e-3 / (args.h * args.n_images)  # lambda\n",
        "args.n_particles = 10 # N"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbrwaBFyRb4P"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXOewTu5Piuw",
        "outputId": "90be1362-1323-41ab-b377-fcf08ad0e4f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:75: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ]
        }
      ],
      "source": [
        "drive.mount(\"/content/gdrive\", force_remount=False) # Mount drive to VM in colab\n",
        "dataset = get_mnist('/content/mnist', args.n_images)  # Load dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define and train model"
      ],
      "metadata": {
        "id": "mDZ3YFSSF5zK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "colab": {
          "background_save": true
        },
        "id": "weq8_THjRHw-"
      },
      "outputs": [],
      "source": [
        "# Define model:\n",
        "model = G(args.x_dim, sigma2=args.likelihood_var, nc=1).to(args.device)\n",
        "\n",
        "# Define training algorithm:\n",
        "pga = PGA(model, dataset, args.h, args.lambd, args.n_particles)\n",
        "\n",
        "# Split dataset into batches for training:\n",
        "training_batches = torch.utils.data.DataLoader(dataset, batch_size=args.n_batch, \n",
        "                                               shuffle=True, pin_memory=True)\n",
        "\n",
        "# Train:\n",
        "losses = []\n",
        "for epoch in range(args.n_epochs):\n",
        "  # model.train()\n",
        "  avg_loss = 0\n",
        "  for imgs, idx in training_batches:\n",
        "      imgs = imgs.to(device=args.device)\n",
        "      loss = pga.step(imgs, idx)\n",
        "      avg_loss += loss\n",
        "      print(\".\", end='')\n",
        "  avg_loss = avg_loss / len(training_batches) \n",
        "  losses.append(avg_loss)\n",
        "  print(f\"Epoch {epoch}: Loss {avg_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2uiBWF1KPSu"
      },
      "outputs": [],
      "source": [
        "# Import modules necessary for training loop\n",
        "%%capture\n",
        "import pickle\n",
        "from torchvision.utils import make_grid\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "to_range_0_1 = lambda x: (x + 1.) / 2.\n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "    n_cols = 8\n",
        "    n_rows = 8\n",
        "    mean = torch.mean(pga._particles, [0, 1, 3, 4])\n",
        "    cov = torch.cov(pga._particles.flatten(0,1).flatten(1, 3).transpose(0, 1))\n",
        "    normal_approx = torch.distributions.multivariate_normal.MultivariateNormal(loc = mean, covariance_matrix=cov)\n",
        "    z = normal_approx.sample(sample_shape=torch.Size([n_cols * n_rows])).unsqueeze(-1).unsqueeze(-1)\n",
        "    samples = to_range_0_1(model(z.to(DEVICE)))\n",
        "    grid = make_grid(samples)\n",
        "    fig = show(grid)\n",
        "    samples = wandb.Image(grid)\n",
        "    (CHECKPOINT_DIR / wandb.run.name / \"grid\").mkdir(exist_ok=True, parents=True)\n",
        "    plt.savefig(CHECKPOINT_DIR / wandb.run.name / \"grid\" / f\"{epoch}_samples.png\", bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "    model.eval()\n",
        "    torch.random.manual_seed(1)\n",
        "    original_img = to_range_0_1(train.dataset[0][0].unsqueeze(0))\n",
        "    particle_img = to_range_0_1(model(pga._particles[0, :10].to(DEVICE))).to(original_img.device)\n",
        "    grid = make_grid(torch.concat([original_img, particle_img], dim=0))\n",
        "    particles = wandb.Image(grid)\n",
        "\n",
        "    mse_n_samples = 100\n",
        "    mse_n_particles = args.n_particles\n",
        "    original_img = to_range_0_1(dataset[:mse_n_samples][0].unsqueeze(1))\n",
        "    particle_img = to_range_0_1(model(pga._particles[:mse_n_samples, :mse_n_particles].contiguous().to(DEVICE))).to(original_img.device)\n",
        "    assert original_img.shape == torch.Size([mse_n_samples, 1, 1, 32, 32])\n",
        "    assert particle_img.shape == torch.Size([mse_n_samples, mse_n_particles, 1, 32, 32])\n",
        "    mse = (((particle_img - original_img) ** 2).sum([-1, -2, -3]).mean()).item()\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    n_missing_img = 10\n",
        "    missing_imgs = dataset[:n_missing_img][0]\n",
        "    init_x = torch.randn(n_missing_img, args.x_dim, 1, 1, requires_grad=True)\n",
        "    opt = torch.optim.Adam([init_x], 1e-2)\n",
        "    mse = torch.nn.MSELoss()\n",
        "    missing_mask = torch.zeros_like(missing_imgs, dtype=torch.bool)\n",
        "\n",
        "    for i in range(10, 22):\n",
        "      for j in range(10, 22):\n",
        "            missing_mask[..., i, j] = True\n",
        "\n",
        "    for i in range(1000):\n",
        "      opt.zero_grad()\n",
        "      filled_imgs = model.forward(init_x.to(DEVICE)).to('cpu')\n",
        "      loss = mse(filled_imgs[~missing_mask], missing_imgs[~missing_mask])\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "\n",
        "\n",
        "    filled_imgs = to_range_0_1(filled_imgs).expand(-1, 3, -1, -1)\n",
        "    missing_imgs = to_range_0_1(missing_imgs).expand(-1, 3, -1, -1)\n",
        "    input = missing_imgs.detach().clone()\n",
        "    input[missing_mask.expand(-1, 3, -1, -1)] = 0.2\n",
        "\n",
        "    for i in range(n_missing_img):\n",
        "      grid = make_grid(torch.concat([input[[i]], filled_imgs[[i]], missing_imgs[[i]]], dim=0))\n",
        "      fig = show(grid)\n",
        "      (CHECKPOINT_DIR / wandb.run.name / \"impaint\" / f\"{epoch}\").mkdir(exist_ok=True, parents=True)\n",
        "      plt.savefig(CHECKPOINT_DIR / wandb.run.name / \"impaint\" / f\"{epoch}\" / f\"{i}.png\", bbox_inches='tight')\n",
        "      plt.close(fig)\n",
        "\n",
        "  if epoch > 2 and args.early_stopping:\n",
        "    if epoch - np.argmin(losses) > 20:\n",
        "      print(\"Early Stop\")\n",
        "      break;\n",
        "\n",
        "    # import matplotlib.pyplot as plt\n",
        "    # particles = pga._particles[:, :mse_n_particles].flatten(0,1).flatten(-3,-1).cpu()\n",
        "    # plt.scatter(particles[:,0], particles[:,1])\n",
        "    # plt.show()\n",
        "  plt.close('all')"
      ],
      "metadata": {
        "id": "bF59nI7COLIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lB6ZLj815WfN",
        "cellView": "code"
      },
      "outputs": [],
      "source": [
        "#@title Plotting function\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "def show(imgs):\n",
        "    if not isinstance(imgs, list):\n",
        "        imgs = [imgs]\n",
        "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False, dpi=400)\n",
        "    for i, img in enumerate(imgs):\n",
        "        img = img.detach()\n",
        "        img = F.to_pil_image(img)\n",
        "        axs[0, i].imshow(np.asarray(img))\n",
        "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E1zwkOW-8f8"
      },
      "outputs": [],
      "source": [
        "plt.close('all')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MNIST.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}