{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParticleEM/ParEM_neural_latent_variable_model/blob/master/notebooks/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set config variables"
      ],
      "metadata": {
        "id": "VjGhesuKY-3I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ssu1R-nnaGpW"
      },
      "outputs": [],
      "source": [
        "# Declare dicitonary-like object for storing config variables:\n",
        "import argparse\n",
        "args = argparse.Namespace()\n",
        "\n",
        "# Data setttings\n",
        "args.n_images = 10000 # Training set size M\n",
        "\n",
        "# Training settings\n",
        "args.n_epochs = 500 # K: total number of iterations\n",
        "args.n_batch = 128 # M_b: batch size for theta-updates\n",
        "args.n_sampler_batch = 750\n",
        "args.seed = 1 # Seed for PRNG\n",
        "\n",
        "# Model Settings\n",
        "args.x_dim = 10 # d_x: dimension of latent space\n",
        "args.likelihood_var = 0.3 ** 2 # \\sigma^2\n",
        "\n",
        "# PGA Settings\n",
        "args.q_step_size = 5e-5 # h: step size \n",
        "args.lambd = 1e-3 / (args.q_step_size * args.n_images) # \\lambda\n",
        "args.theta_step_size = 1e-3 # \\lambda\n",
        "args.n_particles = 10 # N"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceG5fAENPfr6"
      },
      "source": [
        "# Import modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz47uMXqKYf5"
      },
      "source": [
        "First, we load the modules we need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLCqb7XBKj2b"
      },
      "outputs": [],
      "source": [
        "# Install missing modules\n",
        "%%capture\n",
        "!pip install torchtyping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpxVMzKzQGaN"
      },
      "outputs": [],
      "source": [
        "# Import standard modules\n",
        "import torch\n",
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X55L4TEtl385",
        "outputId": "b9bea7bf-b1d8-4d82-c012-f8bc36af2694"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ParEM_VAE'...\n",
            "remote: Enumerating objects: 291, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 291 (delta 26), reused 56 (delta 23), pack-reused 230\u001b[K\n",
            "Receiving objects: 100% (291/291), 42.93 KiB | 4.77 MiB/s, done.\n",
            "Resolving deltas: 100% (134/134), done.\n"
          ]
        }
      ],
      "source": [
        "# Import custom modules\n",
        "!rm -rf ParEM_neural_latent_variable_model\n",
        "!git clone https://pareem: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@github.com/ParticleEM/ParEM_neural_latent_variable_model.git\n",
        "sys.path.append(\"/content/ParEM_neural_latent_variable_model/\")\n",
        "from parem.model import G\n",
        "from parem.pga import PGA, optimisers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C83FbhuRRXc_"
      },
      "source": [
        "# Set paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqT0ajsqRVKi",
        "outputId": "9a84074e-6deb-4941-fd6c-00b0db9af9a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mounts drive to VM in colab.\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=False)\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbrwaBFyRb4P"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXOewTu5Piuw",
        "outputId": "f6218e46-5119-4be9-bd05-b92e8ab2947e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:75: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ]
        }
      ],
      "source": [
        "#@title Load dataset\n",
        "from parem.mnist import get_mnist\n",
        "\n",
        "dataset = get_mnist('/content/mnist', args.n_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "JtEGiGKkS0pm"
      },
      "outputs": [],
      "source": [
        "#@title Divvy up dataset in batches for training.\n",
        "\n",
        "train = torch.utils.data.DataLoader(dataset, batch_size=args.n_batch, shuffle=True, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ue1zy2hKjmlb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchtyping import TensorType\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "optimisers = {'sgd': torch.optim.SGD,\n",
        "              'adagrad': torch.optim.Adagrad,\n",
        "              'rmsprop': torch.optim.RMSprop,\n",
        "              }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rduJTaL4RPB7"
      },
      "outputs": [],
      "source": [
        "model = G(args.x_dim, sigma2=args.likelihood_var, nc=1, use_bn=True).to(DEVICE)\n",
        "pga = PGA(model,\n",
        "          args.n_images,\n",
        "          larger_batch_train,\n",
        "          device='cpu',\n",
        "          theta_step_size=args.theta_step_size,\n",
        "          q_step_size=args.q_step_size,\n",
        "          n_particles=args.n_particles,\n",
        "          clip_grad=args.clip_grad,\n",
        "          theta_opt=args.theta_opt,\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2uiBWF1KPSu"
      },
      "outputs": [],
      "source": [
        "# Import modules necessary for training loop\n",
        "%%capture\n",
        "!pip install wandb\n",
        "import wandb\n",
        "import pickle\n",
        "from torchvision.utils import make_grid\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lB6ZLj815WfN",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Plotting function\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "def show(imgs):\n",
        "    if not isinstance(imgs, list):\n",
        "        imgs = [imgs]\n",
        "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False, dpi=400)\n",
        "    for i, img in enumerate(imgs):\n",
        "        img = img.detach()\n",
        "        img = F.to_pil_image(img)\n",
        "        axs[0, i].imshow(np.asarray(img))\n",
        "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "colab": {
          "background_save": true
        },
        "id": "weq8_THjRHw-"
      },
      "outputs": [],
      "source": [
        "#@title Main training loop\n",
        "to_range_0_1 = lambda x: (x + 1.) / 2.\n",
        "\n",
        "wandb.login()\n",
        "wandb.init(\n",
        "    project=\"particle-em-mnist\",\n",
        "    config = vars(args),\n",
        ")\n",
        "\n",
        "wandb.watch(model, log=\"all\", log_freq=10)\n",
        "\n",
        "losses = []\n",
        "for epoch in range(args.n_epochs):\n",
        "  model.train()\n",
        "  avg_loss = 0\n",
        "  start = time.time()\n",
        "  for imgs, idx in train:\n",
        "      imgs = imgs.to(device=DEVICE)\n",
        "      loss = pga.step(imgs, idx)\n",
        "      avg_loss += loss\n",
        "      print(\".\", end='')\n",
        "  end = time.time()\n",
        "  avg_loss = avg_loss / len(train) #/ args.n_images\n",
        "  losses.append(avg_loss)\n",
        "\n",
        "\n",
        "  print(f\"Epoch {epoch}: {end - start:2f}: Loss {avg_loss}\")\n",
        "\n",
        "  # Save model\n",
        "  (CHECKPOINT_DIR / wandb.run.name / \"model\").mkdir(exist_ok=True, parents=True)\n",
        "  torch.save(model.state_dict(), CHECKPOINT_DIR / wandb.run.name  / \"model\" / f\"{epoch}_model\")\n",
        "  (CHECKPOINT_DIR / wandb.run.name / \"particles\").mkdir(exist_ok=True, parents=True)\n",
        "  with open(CHECKPOINT_DIR / wandb.run.name / \"particles\" / f\"{epoch}_particles\", 'wb') as f:\n",
        "    pickle.dump(pga._particles, f)\n",
        "  \n",
        "\n",
        "  with torch.no_grad():\n",
        "    n_cols = 8\n",
        "    n_rows = 8\n",
        "    mean = torch.mean(pga._particles, [0, 1, 3, 4])\n",
        "    cov = torch.cov(pga._particles.flatten(0,1).flatten(1, 3).transpose(0, 1))\n",
        "    normal_approx = torch.distributions.multivariate_normal.MultivariateNormal(loc = mean, covariance_matrix=cov)\n",
        "    z = normal_approx.sample(sample_shape=torch.Size([n_cols * n_rows])).unsqueeze(-1).unsqueeze(-1)\n",
        "    samples = to_range_0_1(model(z.to(DEVICE)))\n",
        "    grid = make_grid(samples)\n",
        "    fig = show(grid)\n",
        "    samples = wandb.Image(grid)\n",
        "    (CHECKPOINT_DIR / wandb.run.name / \"grid\").mkdir(exist_ok=True, parents=True)\n",
        "    plt.savefig(CHECKPOINT_DIR / wandb.run.name / \"grid\" / f\"{epoch}_samples.png\", bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "    model.eval()\n",
        "    torch.random.manual_seed(1)\n",
        "    original_img = to_range_0_1(train.dataset[0][0].unsqueeze(0))\n",
        "    particle_img = to_range_0_1(model(pga._particles[0, :10].to(DEVICE))).to(original_img.device)\n",
        "    grid = make_grid(torch.concat([original_img, particle_img], dim=0))\n",
        "    particles = wandb.Image(grid)\n",
        "\n",
        "    mse_n_samples = 100\n",
        "    mse_n_particles = args.n_particles\n",
        "    original_img = to_range_0_1(dataset[:mse_n_samples][0].unsqueeze(1))\n",
        "    particle_img = to_range_0_1(model(pga._particles[:mse_n_samples, :mse_n_particles].contiguous().to(DEVICE))).to(original_img.device)\n",
        "    assert original_img.shape == torch.Size([mse_n_samples, 1, 1, 32, 32])\n",
        "    assert particle_img.shape == torch.Size([mse_n_samples, mse_n_particles, 1, 32, 32])\n",
        "    mse = (((particle_img - original_img) ** 2).sum([-1, -2, -3]).mean()).item()\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    n_missing_img = 10\n",
        "    missing_imgs = dataset[:n_missing_img][0]\n",
        "    init_x = torch.randn(n_missing_img, args.x_dim, 1, 1, requires_grad=True)\n",
        "    opt = torch.optim.Adam([init_x], 1e-2)\n",
        "    mse = torch.nn.MSELoss()\n",
        "    missing_mask = torch.zeros_like(missing_imgs, dtype=torch.bool)\n",
        "\n",
        "    for i in range(10, 22):\n",
        "      for j in range(10, 22):\n",
        "            missing_mask[..., i, j] = True\n",
        "\n",
        "    for i in range(1000):\n",
        "      opt.zero_grad()\n",
        "      filled_imgs = model.forward(init_x.to(DEVICE)).to('cpu')\n",
        "      loss = mse(filled_imgs[~missing_mask], missing_imgs[~missing_mask])\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "\n",
        "\n",
        "    filled_imgs = to_range_0_1(filled_imgs).expand(-1, 3, -1, -1)\n",
        "    missing_imgs = to_range_0_1(missing_imgs).expand(-1, 3, -1, -1)\n",
        "    input = missing_imgs.detach().clone()\n",
        "    input[missing_mask.expand(-1, 3, -1, -1)] = 0.2\n",
        "\n",
        "    for i in range(n_missing_img):\n",
        "      grid = make_grid(torch.concat([input[[i]], filled_imgs[[i]], missing_imgs[[i]]], dim=0))\n",
        "      fig = show(grid)\n",
        "      (CHECKPOINT_DIR / wandb.run.name / \"impaint\" / f\"{epoch}\").mkdir(exist_ok=True, parents=True)\n",
        "      plt.savefig(CHECKPOINT_DIR / wandb.run.name / \"impaint\" / f\"{epoch}\" / f\"{i}.png\", bbox_inches='tight')\n",
        "      plt.close(fig)\n",
        "\n",
        "  if epoch > 2 and args.early_stopping:\n",
        "    if epoch - np.argmin(losses) > 20:\n",
        "      print(\"Early Stop\")\n",
        "      break;\n",
        "\n",
        "    # import matplotlib.pyplot as plt\n",
        "    # particles = pga._particles[:, :mse_n_particles].flatten(0,1).flatten(-3,-1).cpu()\n",
        "    # plt.scatter(particles[:,0], particles[:,1])\n",
        "    # plt.show()\n",
        "  wandb.log({'particles': particles,\n",
        "              'samples': samples,\n",
        "              \"loss\" : avg_loss,\n",
        "              'mse': mse,\n",
        "              'theta_step_size' : pga.theta_opt.param_groups[0]['lr'],\n",
        "              })\n",
        "  plt.close('all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E1zwkOW-8f8"
      },
      "outputs": [],
      "source": [
        "plt.close('all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_9XA0cSr1lY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MNIST.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}